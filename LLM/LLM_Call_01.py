import os
import sys
import requests
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()


def call(prompt):
    """
    Sends the input prompt to the GPT-4 model via a direct HTTP POST request and returns the assistant's response.

    Parameters:
    - prompt (str): The user's input prompt.

    Returns:
    - str: The assistant's response generated by GPT-4.
    """
    # Retrieve the API key from an environment variable
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("Error: The OpenAI API key is not set. Please set it as an environment variable 'OPENAI_API_KEY'.")

    # Set the request headers including the Authorization header with the API key
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }



    # model 'o1-mini' 65k output
    # model 'gpt-4o-2024-08-06' 16k but supports structured output
    # Prepare the data payload
    data = {
        "model": "o1-mini",
        #"temperature": 0,
        "messages": [
            {"role": "user", "content": prompt },
        ]
    }

    # Make the POST request to the OpenAI API endpoint
    try:
        response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=data)
        response.raise_for_status()  # Raise an error for bad status codes

        # Parse the response JSON and extract the assistant's reply
        content = response.json()['choices'][0]['message']['content']
        return content

    except requests.exceptions.HTTPError as http_err:
        raise RuntimeError(f"HTTP error occurred: {http_err} - {response.text}")
    except Exception as err:
        raise RuntimeError(f"An error occurred: {err}")


# Example usage
if __name__ == "__main__":
    # Check if both the prompt file and data file path are provided as command-line arguments
    if len(sys.argv) < 3:
        print("Usage: python LLM_Call.py <prompt_file> <data_file_path>")
        sys.exit(1)

    prompt_file_path = sys.argv[1]  # Get the prompt file path from the first argument
    data_file_path = sys.argv[2]  # Get the data file path from the second argument

    # Read the prompt file content
    try:
        with open(prompt_file_path, 'r', encoding='utf-8') as prompt_file:
            user_prompt = prompt_file.read()
    except Exception as e:
        print(f"Error reading prompt file: {e}")
        sys.exit(1)

    # Read the data file content
    str_data = "#DATA#"
    entries = os.listdir(data_file_path)
    for file in entries:
        try:
            with open(data_file_path+file, 'r', encoding='utf-8') as data_file:
                data_content = data_file.read()
        except Exception as e:
            print(f"Error reading data file: {e}")
            sys.exit(1)
        str_data+=file + '\n' + data_content + '\n'

    # Combine the prompt and data content with '#DATA#' separator
    combined_prompt = f"{user_prompt} #DATA# {str_data}"

    # Call the API and print the response
    try:
        reply = call(combined_prompt)
        print("\nAssistant's response:")
        print(reply)
    except Exception as e:
        print(str(e))